{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 텐서플로우 다중 레이어 뉴럴 네트워크\n",
    "### -First Contact with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 기본설정\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 그래프 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# batch_size만큼의 랜덤한 데이터 추출    \n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    X_batch, y_batch = [],[]\n",
    "    for batch_idx in range(batch_size): # np.array_split(A,B) :  A array를 B개로 쪼개라\n",
    "        X_batch.append(X[rnd_idx[batch_idx]])\n",
    "        y_batch.append(y[rnd_idx[batch_idx]])\n",
    "    return np.array(X_batch), arrayToOnehot(np.array(y_batch),10)\n",
    "\n",
    "# 숫자를 OneHot으로 바꾸기\n",
    "def arrayToOnehot(array, length):\n",
    "    size = len(array)\n",
    "    onehot = np.zeros((size,length))\n",
    "    onehot[np.arange(size), array] = 1\n",
    "    return onehot\n",
    "\n",
    "# 데이터를 이미지로\n",
    "def ShowImage(array):\n",
    "    with tf.Session() as sess:\n",
    "        image = np.array(array, dtype = 'float')\n",
    "        pixels = image.reshape((28,28))\n",
    "        plt.imshow(pixels, cmap ='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 콘볼루션 뉴럴 네트워크 (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특징  <br>\n",
    "    - 이미지 데이터를 받는 것으로 뉴럴 네트워크를 효율적으로 구함\n",
    "    - 가중치 행렬 W와 바이어스 b를 히든레이어의 모든 뉴런 이 공유\n",
    "       <br>(필요한 가중치 파라메터의 수가 감소 -> 효율)\n",
    "<br><br>\n",
    "- 주 목적  <br>\n",
    "테두리 (edge), 선 (line), 색깔 등 이미지의 시각적 특징이나 성질을 감지\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN을 통한 mnist 손글씨 이미지 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불어오기\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "X_valid, y_valid = shuffle_batch(X_valid, y_valid, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", shape=[None, 28*28])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터를 원래 이미지의 크기로 재구성\n",
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째와 세번째의 차원 : 넓이와 높이\n",
    "마지막 차원 : 컬러 채널\n",
    "![콘뉴네1](https://tensorflowkorea.files.wordpress.com/2016/05/image072.png?w=300&h=282)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN의 두가지 기본원리\n",
    "- 필터 (filter)  \n",
    "<br>\n",
    "- 특성 맵(characteristic map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터가 1st 히든레이어 뉴런에 완전히 연결되어 있지 않음  \n",
    "<br>\n",
    "![콘뉴네2](https://tensorflowkorea.files.wordpress.com/2016/05/image074.png?w=625)  \n",
    "<br>\n",
    "이 예에서 히든 레이어의 각 뉴런은 입력레이어의 5 * 5 영역과 연결  \n",
    "<br>\n",
    "이 5 * 5 영역의 윈도우가 28 * 28 의 입력 레이어를 쭉 훓는다고 생각하면 됨  \n",
    "<br>\n",
    "![콘뉴네3](https://tensorflowkorea.files.wordpress.com/2016/05/image076.png?w=625)  \n",
    "<br>\n",
    "즉, 위와 같은 그림이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스트라이드(stride)  <br>\n",
    "콘볼루션 레이어(Convoluted hiddon layer)에서 한번에 1픽셀 이상 움직일 수도 있음. 그때 사용하는 파라메터  \n",
    "<br>\n",
    "- 패딩(padding)  <br>\n",
    "입력 이미지 밖으로 5 * 5 윈도우가 넘어갈 수 있도록 0(또는 다른 값)으로 테두리를 채우는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 W와 바이어스 b를 CNN에서 보통 커널(kernel) 혹은 필터라 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 커널은 이미지에서 한 종류의 특징만을 감지\n",
    "<br>\n",
    "따라서 감지하고 싶은 각 특징에 한개씩 여러 커널을 사용하는 것이 좋음\n",
    "<br><br>\n",
    "CNN에서는 완전한 콘볼루션 레이어는 여러게의 커널로 구성\n",
    "\n",
    "![콘뉴네4](https://tensorflowkorea.files.wordpress.com/2016/05/image078.png?w=625)\n",
    "<br><br>\n",
    "이 예에서는 32개의 커널을 사용\n",
    "<br><br>\n",
    "각 커널은 5 * 5 가중치 행렬 W와 한개의 바이어스 b로 정의되고 이 히든 레이어의 뉴런들에 공통적으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치를 난수값(random noise)로 초기화\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 바이어스를 작응 양수로 초기화\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 콘볼루션 레이어 외에 풀링(pooling) 레이어가 콘볼루션 레이어 뒤에 따라 옴\n",
    "<br>\n",
    "- 풀링 레이어\n",
    "    - 콘볼루션 레이어의 출력을 단순화\n",
    "    - 콘볼루션 레이어가 생산한 정보를 컴팩트한 버전으로 만듬\n",
    "    \n",
    "![콘뉴네5](https://tensorflowkorea.files.wordpress.com/2016/05/image080.png?w=625)\n",
    "<br>\n",
    "(이 예제에서는 풀링방법 중 max_pooling을 사용)\n",
    "* max-pooling : \n",
    "2 * 2 영역에서 가장 큰 값을 선택해서 정보를 압축\n",
    "\n",
    "![콘뉴네6](https://tensorflowkorea.files.wordpress.com/2016/05/image082.png?w=625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콘볼루션 레이어1\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(윈도우 사이즈), (윈도우사이즈), (컬러 채널), (특징수)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReLU (Rectified Linear Unit)\n",
    "    - 딥 뉴럴 네트워크의 히든레이어에서 사용되는 기본 활성화 함수\n",
    "    - 음수면 0을, 양수면 그대로 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콘볼루션 레이어2\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(윈도우 사이즈), (윈도우사이즈), (이전 레이어의 출력값 크기), (특징수)]\n",
    "<br>\n",
    "12 * 12 크기의 행렬에 스트라이드 1로 5 * 5 윈도우를 적용했기 때문에 결과의 크기 7 * 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 레이어에 주입하기 위해 7 * 7 출력 값을 완전연결 레이어에 연결\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(콘볼루션레이어 크기 7 * &) * (필터 수), (임의로 선택한 뉴런 개수)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서를 벡터로 변환 (소프트맥스에 넣기 위해)\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "# 활성함수 적용\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 드롭 아웃 (dorpout)\n",
    "    - 뉴럴 네트워크에서 필요한 파라메타 수를 줄임\n",
    "    - 무작위로 노드를 삭제해 그 입력과 출력 연결을 제거\n",
    "    - 오버피팅을 예방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭 아웃이 되지 않을 확률\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "# 드롭 아웃\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트 맥스 레이어\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "test accuracy 0.8312\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        batch = shuffle_batch(X_train,y_train,50)\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = sess.run( accuracy, feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        sess.run(train_step,feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print(\"test accuracy %g\"% sess.run(accuracy, feed_dict={ x: X_valid, y_: y_valid, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
