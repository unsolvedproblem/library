{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 12500\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = 'datasets/cat_dog/train'\n",
    "TEST_DIR = 'datasets/cat_dog/test'\n",
    "\n",
    "print(len(os.listdir(TRAIN_DIR)),len(os.listdir(TEST_DIR)))\n",
    "\n",
    "train_image_file_names = [TRAIN_DIR + '/' + i for i in os.listdir(TRAIN_DIR)][12000:13000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(image_file_names, width=500, height=500, final_width=214, final_height=214):\n",
    "    import scipy.misc\n",
    "    \n",
    "    def resize_width_height(image, width=width, height=width, final_width=final_width, final_height=final_height):\n",
    "        tmp = np.zeros((width,height,3))\n",
    "        tmp[:image.shape[0], :image.shape[1], :] = image\n",
    "        tmp = scipy.misc.imresize(tmp, (final_width,final_height))\n",
    "        tmp = tmp/ 255\n",
    "        return tmp.reshape(-1, final_width, final_height, 3) ## batch, width, height, channel\n",
    "    \n",
    "    data = np.zeros((1, final_width, final_height, 3))\n",
    "    num = 0\n",
    "    for i in image_file_names:\n",
    "        tmp = mpimg.imread(i)\n",
    "        data = np.r_[data, resize_width_height(tmp)]\n",
    "        if num % 10 == 0:\n",
    "            print(\"아직 문제 없습니다.\", num, end='\\r')\n",
    "        num += 1\n",
    "    return data[1:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아직 문제 없습니다. 490\r"
     ]
    }
   ],
   "source": [
    "train_data0 = create_data(train_image_file_names[:500]) \n",
    "## train_image_file은 이미지 주소가 있는 str입니다.\n",
    "# test_data0 = create_data(test_image_file_names[:500])\n",
    "\n",
    "train_data1 = create_data(train_image_file_names[500:]) \n",
    "## train_image_file은 이미지 주소가 있는 str입니다.\n",
    "#test_data1 = create_data(test_image_file_names[500:])\n",
    "\n",
    "train_data = np.r_[train_data0, train_data1]\n",
    "# test_data = np.r_[test_data0, test_data1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 214, 214, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([[1., 0.] if 'dog' in name[23:] else [0., 1.] for name in train_image_file_names])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = tf.placeholder(\"float\", shape=[None, 214, 214, 3])\n",
    "y = tf.placeholder(\"float\", shape=[None, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치를 표준편차 0.1을 갖는 난수로 초기화하는 함수와 바이어스를 0.1로 초기화하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stride는 1로 하고 패딩은 0으로 하는 합성곱층을 만드는 함수와 2 $\\times$ 2 최대 풀링 레이어와 평균 풀링 레이어를 위한 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\"):\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding=padding)\n",
    "\n",
    "def max_pool_3x3(x, padding=\"SAME\"):\n",
    "    return tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,2,2,1], padding=padding)\n",
    "\n",
    "def avg_pool_7x7(x, padding=\"VALID\"):\n",
    "    return tf.nn.avg_pool(x, ksize=[1,7,7,1], strides=[1,1,1,1], padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 합성곱층을 만들기 위해 가중치와 바이어스 텐서를 만들고, 활성화함수는 ReLU 함수를 사용합니다. 그리고 합성곱층 뒤에 최대 풀링층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([7,7,3,64]) ## 수용장 너비, 수용장 높이, 컬러, 특성 맵 개수\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(X_image, W_conv1, strides=[1,2,2,1]) + b_conv1)\n",
    "\n",
    "h_pool1 = max_pool_3x3(h_conv1)\n",
    "\n",
    "lrn_conv1 = tf.nn.lrn(h_pool1, depth_radius=2, bias=1,\n",
    "                          alpha=0.00002, beta=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 합성곱층과 세 번쨰 합성곱층을 만들기 위해 가중치와 바이어스 텐서를 만들고, 활성화함수는 ReLU 함수를 사용합니다. 그리고 합성곱층 뒤에 정규화 함수를 추가한 후 최대 풀링층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([1,1,64,64]) ## 수용장 너비, 수용장 높이, 컬러, 특성 맵 개수\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(lrn_conv1, W_conv2, strides=[1,1,1,1]) + b_conv2)\n",
    "\n",
    "W_conv3 = weight_variable([3,3,64,192]) ## 수용장 너비, 수용장 높이, 컬러, 특성 맵 개수\n",
    "b_conv3 = bias_variable([192])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, strides=[1,1,1,1]) + b_conv3)\n",
    "\n",
    "lrn_conv2 = tf.nn.lrn(h_conv3, depth_radius=2, bias=1,\n",
    "                          alpha=0.00002, beta=0.75)\n",
    "\n",
    "h_pool2 = max_pool_3x3(lrn_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 인셉션 모듈을 만들어보겠습니다. 인셉션 모듈을 편하게 사용하기위해 함수로 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(x, in_channels, filter_count):\n",
    "    # 1x1 1\n",
    "    W_incep1  = weight_variable([1,1,in_channels, filter_count[0]])\n",
    "    b_incep1 = bias_variable([filter_count[0]])\n",
    "    one_by_one1 = tf.nn.relu(conv2d(x, W_incep1, strides=[1,1,1,1]) + b_incep1)\n",
    "    \n",
    "    # 1x1 2, 3x3 \n",
    "    W_incep2  = weight_variable([1,1,in_channels, filter_count[1]])\n",
    "    b_incep2 = bias_variable([filter_count[1]])\n",
    "    one_by_one2 = tf.nn.relu(conv2d(x, W_incep2, strides=[1,1,1,1]) + b_incep2)\n",
    "    \n",
    "    W_incep3x3  = weight_variable([3,3,filter_count[1], filter_count[2]])\n",
    "    b_incep3x3 = bias_variable([filter_count[2]])\n",
    "    three_by_three = tf.nn.relu(conv2d(one_by_one2, W_incep3x3, strides=[1,1,1,1]) + b_incep3x3)\n",
    "    \n",
    "    # 1x1 3, 5x5\n",
    "    W_incep3  = weight_variable([1,1,in_channels, filter_count[3]])\n",
    "    b_incep3 = bias_variable([filter_count[3]])\n",
    "    one_by_one3 = tf.nn.relu(conv2d(x, W_incep3, strides=[1,1,1,1]) + b_incep3)\n",
    "   \n",
    "    W_incep5x5  = weight_variable([5,5,filter_count[3], filter_count[4]])\n",
    "    b_incep5x5 = bias_variable([filter_count[4]])\n",
    "    five_by_five = tf.nn.relu(conv2d(one_by_one3, W_incep5x5, strides=[1,1,1,1]) + b_incep5x5)\n",
    "   \n",
    "    # max pool, 1x1 4\n",
    "    max_pool = tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "    W_incep4  = weight_variable([1,1,in_channels, filter_count[5]])\n",
    "    b_incep4 = bias_variable([filter_count[5]])\n",
    "    one_by_one4 = tf.nn.relu(conv2d(max_pool, W_incep4, strides=[1,1,1,1]) + b_incep4)\n",
    "    \n",
    "    ## concat\n",
    "    \n",
    "    x = tf.concat([one_by_one1, three_by_three, five_by_five, one_by_one4], axis=3)\n",
    "    \n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,2 번째 인셉션 모듈을 만들겠습니다. 그리고 최대 풀링층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(480)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_incep1 = inception(h_pool2, in_channels=192, filter_count=[64,96,128,16,32,32])\n",
    "h_incep2 = inception(h_incep1, in_channels=64+128+32+32, filter_count=[128,128,192,32,96,64])\n",
    "\n",
    "h_pool3 = max_pool_3x3(h_incep2)\n",
    "h_pool3.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3,4,5,6,7 번째 인셉션 모듈을 추가하겠습니다. 그리고 최대 풀링층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(832)])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_incep3 = inception(h_pool3, in_channels=480, filter_count=[192,96,208,16,48,64])\n",
    "h_incep4 = inception(h_incep3, in_channels=192+208+48+64, filter_count=[160,112,224,24,64,64])\n",
    "h_incep5 = inception(h_incep4, in_channels=160+224+64+64, filter_count=[128,128,256,24,64,64])\n",
    "h_incep6 = inception(h_incep5, in_channels=128+256+64+64, filter_count=[112,144,288,32,64,64])\n",
    "h_incep7 = inception(h_incep6, in_channels=112+288+64+64, filter_count=[256,160,320,32,128,128])\n",
    "\n",
    "h_pool4 = max_pool_3x3(h_incep7)\n",
    "h_pool4.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8, 9 번째 인셉션 모듈을 추가하겠습니다. 그리고 평균 풀링층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(1024)])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_incep8 = inception(h_pool4, in_channels=832, filter_count=[256,160,320,32,128,128])\n",
    "h_incep9 = inception(h_incep8, in_channels=256+320+128+128, filter_count=[384,192,384,48,128,128])\n",
    "\n",
    "h_pool5 = avg_pool_7x7(h_incep9)\n",
    "h_pool5.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드랍아웃 층을 추가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_pool5, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전 연결층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([1 * 1 * 1024, 1000]) ## 4096는 뉴런 개수\n",
    "b_fc1 = bias_variable([1000])\n",
    "\n",
    "h_fc1_drop_flat = tf.reshape(h_fc1_drop, [-1, 1 * 1 * 1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_fc1_drop_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax층과 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1000, 2])\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "k = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "y_conv = tf.nn.softmax(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실함수는 cross entropy로 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-78-da9342bf3981>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y, logits=k)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "러닝 알고리즘을 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 정확도 함수를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망을 훈련 시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 미니 배치 데이터 정확도: 0.68\n",
      "5 미니 배치 데이터 정확도: 0.68\n",
      "10 미니 배치 데이터 정확도: 0.6\n",
      "15 미니 배치 데이터 정확도: 0.68\n",
      "20 미니 배치 데이터 정확도: 0.48\n",
      "25 미니 배치 데이터 정확도: 0.56\n",
      "30 미니 배치 데이터 정확도: 0.36\n",
      "35 미니 배치 데이터 정확도: 0.44\n",
      "epoch 0 인 데이터 정확도: 0.44\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.36\n",
      "15 미니 배치 데이터 정확도: 0.32\n",
      "20 미니 배치 데이터 정확도: 0.44\n",
      "25 미니 배치 데이터 정확도: 0.4\n",
      "30 미니 배치 데이터 정확도: 0.4\n",
      "35 미니 배치 데이터 정확도: 0.68\n",
      "epoch 1 인 데이터 정확도: 0.6\n",
      "0 미니 배치 데이터 정확도: 0.36\n",
      "5 미니 배치 데이터 정확도: 0.6\n",
      "10 미니 배치 데이터 정확도: 0.32\n",
      "15 미니 배치 데이터 정확도: 0.4\n",
      "20 미니 배치 데이터 정확도: 0.52\n",
      "25 미니 배치 데이터 정확도: 0.56\n",
      "30 미니 배치 데이터 정확도: 0.6\n",
      "35 미니 배치 데이터 정확도: 0.56\n",
      "epoch 2 인 데이터 정확도: 0.72\n",
      "0 미니 배치 데이터 정확도: 0.56\n",
      "5 미니 배치 데이터 정확도: 0.4\n",
      "10 미니 배치 데이터 정확도: 0.44\n",
      "15 미니 배치 데이터 정확도: 0.52\n",
      "20 미니 배치 데이터 정확도: 0.6\n",
      "25 미니 배치 데이터 정확도: 0.48\n",
      "30 미니 배치 데이터 정확도: 0.36\n",
      "35 미니 배치 데이터 정확도: 0.32\n",
      "epoch 3 인 데이터 정확도: 0.48\n",
      "0 미니 배치 데이터 정확도: 0.36\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.6\n",
      "15 미니 배치 데이터 정확도: 0.56\n",
      "20 미니 배치 데이터 정확도: 0.56\n",
      "25 미니 배치 데이터 정확도: 0.4\n",
      "30 미니 배치 데이터 정확도: 0.52\n",
      "35 미니 배치 데이터 정확도: 0.76\n",
      "epoch 4 인 데이터 정확도: 0.48\n",
      "0 미니 배치 데이터 정확도: 0.48\n",
      "5 미니 배치 데이터 정확도: 0.36\n",
      "10 미니 배치 데이터 정확도: 0.56\n",
      "15 미니 배치 데이터 정확도: 0.44\n",
      "20 미니 배치 데이터 정확도: 0.6\n",
      "25 미니 배치 데이터 정확도: 0.6\n",
      "30 미니 배치 데이터 정확도: 0.6\n",
      "35 미니 배치 데이터 정확도: 0.44\n",
      "epoch 5 인 데이터 정확도: 0.48\n",
      "0 미니 배치 데이터 정확도: 0.56\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.4\n",
      "15 미니 배치 데이터 정확도: 0.56\n",
      "20 미니 배치 데이터 정확도: 0.56\n",
      "25 미니 배치 데이터 정확도: 0.32\n",
      "30 미니 배치 데이터 정확도: 0.6\n",
      "35 미니 배치 데이터 정확도: 0.64\n",
      "epoch 6 인 데이터 정확도: 0.64\n",
      "0 미니 배치 데이터 정확도: 0.44\n",
      "5 미니 배치 데이터 정확도: 0.48\n",
      "10 미니 배치 데이터 정확도: 0.44\n",
      "15 미니 배치 데이터 정확도: 0.64\n",
      "20 미니 배치 데이터 정확도: 0.44\n",
      "25 미니 배치 데이터 정확도: 0.56\n",
      "30 미니 배치 데이터 정확도: 0.68\n",
      "35 미니 배치 데이터 정확도: 0.52\n",
      "epoch 7 인 데이터 정확도: 0.6\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.64\n",
      "10 미니 배치 데이터 정확도: 0.6\n",
      "15 미니 배치 데이터 정확도: 0.6\n",
      "20 미니 배치 데이터 정확도: 0.52\n",
      "25 미니 배치 데이터 정확도: 0.4\n",
      "30 미니 배치 데이터 정확도: 0.56\n",
      "35 미니 배치 데이터 정확도: 0.52\n",
      "epoch 8 인 데이터 정확도: 0.64\n",
      "0 미니 배치 데이터 정확도: 0.64\n",
      "5 미니 배치 데이터 정확도: 0.4\n",
      "10 미니 배치 데이터 정확도: 0.56\n",
      "15 미니 배치 데이터 정확도: 0.6\n",
      "20 미니 배치 데이터 정확도: 0.72\n",
      "25 미니 배치 데이터 정확도: 0.4\n",
      "30 미니 배치 데이터 정확도: 0.48\n",
      "35 미니 배치 데이터 정확도: 0.52\n",
      "epoch 9 인 데이터 정확도: 0.64\n",
      "0 미니 배치 데이터 정확도: 0.44\n",
      "5 미니 배치 데이터 정확도: 0.6\n",
      "10 미니 배치 데이터 정확도: 0.68\n",
      "15 미니 배치 데이터 정확도: 0.6\n",
      "20 미니 배치 데이터 정확도: 0.52\n",
      "25 미니 배치 데이터 정확도: 0.52\n",
      "30 미니 배치 데이터 정확도: 0.36\n",
      "35 미니 배치 데이터 정확도: 0.6\n",
      "epoch 10 인 데이터 정확도: 0.32\n",
      "0 미니 배치 데이터 정확도: 0.56\n",
      "5 미니 배치 데이터 정확도: 0.4\n",
      "10 미니 배치 데이터 정확도: 0.4\n",
      "15 미니 배치 데이터 정확도: 0.32\n",
      "20 미니 배치 데이터 정확도: 0.64\n",
      "25 미니 배치 데이터 정확도: 0.6\n",
      "30 미니 배치 데이터 정확도: 0.64\n",
      "35 미니 배치 데이터 정확도: 0.48\n",
      "epoch 11 인 데이터 정확도: 0.52\n",
      "0 미니 배치 데이터 정확도: 0.56\n",
      "5 미니 배치 데이터 정확도: 0.32\n",
      "10 미니 배치 데이터 정확도: 0.56\n",
      "15 미니 배치 데이터 정확도: 0.52\n",
      "20 미니 배치 데이터 정확도: 0.4\n",
      "25 미니 배치 데이터 정확도: 0.36\n",
      "30 미니 배치 데이터 정확도: 0.6\n",
      "35 미니 배치 데이터 정확도: 0.52\n",
      "epoch 12 인 데이터 정확도: 0.6\n",
      "0 미니 배치 데이터 정확도: 0.64\n",
      "5 미니 배치 데이터 정확도: 0.56\n",
      "10 미니 배치 데이터 정확도: 0.44\n",
      "15 미니 배치 데이터 정확도: 0.52\n",
      "20 미니 배치 데이터 정확도: 0.36\n",
      "25 미니 배치 데이터 정확도: 0.44\n",
      "30 미니 배치 데이터 정확도: 0.64\n",
      "35 미니 배치 데이터 정확도: 0.4\n",
      "epoch 13 인 데이터 정확도: 0.4\n",
      "0 미니 배치 데이터 정확도: 0.4\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.36\n",
      "15 미니 배치 데이터 정확도: 0.52\n",
      "20 미니 배치 데이터 정확도: 0.52\n",
      "25 미니 배치 데이터 정확도: 0.52\n",
      "30 미니 배치 데이터 정확도: 0.44\n",
      "35 미니 배치 데이터 정확도: 0.48\n",
      "epoch 14 인 데이터 정확도: 0.44\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.4\n",
      "10 미니 배치 데이터 정확도: 0.56\n",
      "15 미니 배치 데이터 정확도: 0.6\n",
      "20 미니 배치 데이터 정확도: 0.52\n",
      "25 미니 배치 데이터 정확도: 0.68\n",
      "30 미니 배치 데이터 정확도: 0.48\n",
      "35 미니 배치 데이터 정확도: 0.6\n",
      "epoch 15 인 데이터 정확도: 0.64\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.52\n",
      "10 미니 배치 데이터 정확도: 0.64\n",
      "15 미니 배치 데이터 정확도: 0.56\n",
      "20 미니 배치 데이터 정확도: 0.24\n",
      "25 미니 배치 데이터 정확도: 0.4\n",
      "30 미니 배치 데이터 정확도: 0.52\n",
      "35 미니 배치 데이터 정확도: 0.4\n",
      "epoch 16 인 데이터 정확도: 0.56\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.6\n",
      "15 미니 배치 데이터 정확도: 0.48\n",
      "20 미니 배치 데이터 정확도: 0.44\n",
      "25 미니 배치 데이터 정확도: 0.52\n",
      "30 미니 배치 데이터 정확도: 0.68\n",
      "35 미니 배치 데이터 정확도: 0.52\n",
      "epoch 17 인 데이터 정확도: 0.68\n",
      "0 미니 배치 데이터 정확도: 0.48\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.44\n",
      "15 미니 배치 데이터 정확도: 0.64\n",
      "20 미니 배치 데이터 정확도: 0.4\n",
      "25 미니 배치 데이터 정확도: 0.32\n",
      "30 미니 배치 데이터 정확도: 0.48\n",
      "35 미니 배치 데이터 정확도: 0.68\n",
      "epoch 18 인 데이터 정확도: 0.48\n",
      "0 미니 배치 데이터 정확도: 0.44\n",
      "5 미니 배치 데이터 정확도: 0.44\n",
      "10 미니 배치 데이터 정확도: 0.52\n",
      "15 미니 배치 데이터 정확도: 0.52\n",
      "20 미니 배치 데이터 정확도: 0.52\n",
      "25 미니 배치 데이터 정확도: 0.48\n",
      "30 미니 배치 데이터 정확도: 0.36\n",
      "35 미니 배치 데이터 정확도: 0.36\n",
      "epoch 19 인 데이터 정확도: 0.52\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.6\n",
      "10 미니 배치 데이터 정확도: 0.48\n",
      "15 미니 배치 데이터 정확도: 0.4\n",
      "20 미니 배치 데이터 정확도: 0.48\n",
      "25 미니 배치 데이터 정확도: 0.52\n",
      "30 미니 배치 데이터 정확도: 0.52\n",
      "35 미니 배치 데이터 정확도: 0.64\n",
      "epoch 20 인 데이터 정확도: 0.56\n",
      "0 미니 배치 데이터 정확도: 0.52\n",
      "5 미니 배치 데이터 정확도: 0.36\n",
      "10 미니 배치 데이터 정확도: 0.4\n",
      "15 미니 배치 데이터 정확도: 0.48\n",
      "20 미니 배치 데이터 정확도: 0.68\n",
      "25 미니 배치 데이터 정확도: 0.52\n",
      "30 미니 배치 데이터 정확도: 0.6\n",
      "35 미니 배치 데이터 정확도: 0.44\n",
      "epoch 21 인 데이터 정확도: 0.4\n",
      "0 미니 배치 데이터 정확도: 0.36\n",
      "5 미니 배치 데이터 정확도: 0.48\n",
      "10 미니 배치 데이터 정확도: 0.48\n",
      "15 미니 배치 데이터 정확도: 0.44\n",
      "20 미니 배치 데이터 정확도: 0.44\n",
      "25 미니 배치 데이터 정확도: 0.44\n",
      "30 미니 배치 데이터 정확도: 0.48\n",
      "35 미니 배치 데이터 정확도: 0.56\n",
      "epoch 22 인 데이터 정확도: 0.64\n",
      "0 미니 배치 데이터 정확도: 0.28\n",
      "5 미니 배치 데이터 정확도: 0.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-d780127d735c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshuffle_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_conv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX_image\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0macc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX_image\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 25\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        num = 0\n",
    "        for X_batch, y_batch in shuffle_batch(train_data, labels, batch_size):\n",
    "            _, y_pred = sess.run([train_step, y_conv], feed_dict={X_image: X_batch, y: y_batch, keep_prob: 0.5})\n",
    "            if num % 10 == 0:\n",
    "                acc_batch = accuracy.eval(feed_dict={X_image: X_batch, y: y_batch, keep_prob: 0.5})\n",
    "                print(num, \"미니 배치 데이터 정확도:\", acc_batch)\n",
    "            num += 1\n",
    "        \n",
    "        acc_batch = accuracy.eval(feed_dict={X_image: X_batch, y: y_batch, keep_prob: 0.4})\n",
    "        print('epoch', epoch, \"인 데이터 정확도:\", acc_batch)        \n",
    "        \n",
    "    save_path = saver.save(sess, \"./cnn_alexnet.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
